<h1><center>모델 피팅 및 결과도출</center></h1>



## 문서 개요

이 문서는 model.zip폴더에 담겨있는 코드에 대한 설명으로서, 모델을 어떻게 피팅했고, 결과를 도출했는지에 대한 정보가 있습니다. 디렉토리 순서대로 설명할 것이며, 설명 순서는 아래와 같습니다.

1. data 폴더
2. model_basic(time) 폴더
3. util 폴더
4. result 폴더
5. main_train(test).py





## 1. data

### 1-1 extra_data

상품명 별 상품군, 마더코드, 상품코드 정보를 담고 있는 name_code.csv 파일과 상품명들의 유사도 정보를 담고 있는 name_sim.csv 파일을 넣은 폴더입니다. 또한 최적화에 필요한 각종 정보를 담고있는 파일입니다.

### 1-2 preprocessed_data

이곳에 모델에 피팅시킬 데이터를 넣어 놓습니다. preprocess2_test(train){num}_{num}.csv(2. 데이터 전처리.ipynb 파일을 통해서 나온 데이터) 데이터를 넣어놓는 폴더 입니다.  



### 1-3 data_preprocessing.py

데이터를 읽고 모델에 넣기위해 최종적으로 전처리 하는 곳입니다. main.py의 여러 하이퍼 파라미터와 연결되도록 설계했으며, 구체적인 전처리 방법은 하이퍼 파라미터 설명과 연관지어 main.py에서 설명하겠습니다.





## 2. model_basic(time)

학습시킬 딥러닝 모델 class를 저장하는 곳으로써, 이곳의 모델 class를 불러와 사용합니다.

### 2-1 model_basic

비 시계열 기반의 모델을 저장하는 곳입니다. 최종적으로 가장 성과가 좋게 나온 모델 하나만을 남겨두었습니다.



### 2-2 model_time

시계열 기반의 모델을 저장하는 곳입니다. 이 폴더의 모델은 사용할 수 없습니다. 시계열 기반모델이 홈쇼핑 데이터에 잘 작동하지 않았기 때문에, 최종적으로 코드 정리를 할 때 시계열 기반 모델을 사용할 수 있도록 연결하지 않았습니다. 이전에 사용했던 모델 중 하나만을 기록으로 남겨 놓았고 추가적인 코딩을 통해서 사용할 수 있습니다.



## 3. util

### 3-1 util.py

1. 자주 사용되는 함수를 정의해놓았습니다.
2. cal_MAPE: MAPE를 자동으로 계산해주는 함수입니다.
3. prepare_sim_matrix: 모델을 training할때 데이터에 해당하는 상품군, 마더코드, 상품코드 뿐만 아니라 유사한 상품명을 가진 데이터의 상품군, 마더코드, 상품코드에 대해서도 훈련을 시키는데, 이러한 훈련을 위한 데이터를 만들어주는 함수입니다.
4. make_embedding(_for_test): 대부분의 데이터를 embedding 벡터로 변환하여 작업을 진행하는데,  embedding벡터를 만들어주는 함수입니다. _for_test는 test를 위한 버젼입니다. _for_opt는 최적화 편성표를 만들기 위한 위한 버젼입니다.
5. cal_y_for_opt, prepare_x_embedding_for_opt, arrange_result_matrix, assign_result: 최적화 편성표를 만들기위한 함수입니다.
6. write_loss(1,2): train(test)_loss 등 모델선택에 도움을 주는 여러 수치를 기록하는 함수입니다.
7. FC_embedding_model_save(load): 제일 좋은 성과를 낸 모델을 저장하고 load하는데 사용합니다.



### 3-2 _1_FC_based_class.py

1. main에서는 hyper parameter만 넣고 작동을 할 수 있도록 class형태로 만들었습니다.
2. fc_based는 비시계열 기반 딥러닝 모델을 사용했다는 것을 의미합니다.
3. object를 만드는 부분(\__init__)에서 데이터를 만들고, fit 메소드에서 피팅합니다. 또한, predict 메소드에서 예측하고 optimize 메소드에서 최적의 시간표를 만들어냅니다.



## 4. result

필요한 중간결과들이 저장돼 있습니다.



## 5. main_train(test).py

### 5-1. main_train.py

1. main_train에서는 hyperparameter를 결정하고 실제 모델을 훈련시키고 결과를 도출합니다.

2. hyperparameter part

   - model hyperparameter

     ```python
     # 사용할 class(시계열 기반을 사용하지 않았기 때문에 1개만 선택할 수 있습니다.)
     from util._1_FC_based_class import FCClass 
     
     # 사용할 딥러닝 model(위에 비 시계열 기반의 class를 선택했기 때문에 비 시계열 기반의 model만 선택할 수 있으며, 가장 성과가 좋은 모델 하나만 남겨놓아서 1개만 선택할 수 있습니다.)
     from model_basic.resnet import ResNet
     
     # embedding에 사용되는 model과 전체적 fitting에 사용되는 모델을 학습시키기 위한 adam optimizer의 learning_rate, beta, weight_decay 인자입니다.
     E_lr, FC_lr = 1e-4, 1e-4
     E_beta, FC_beta = (0.5,0.9), (0.5,0.9)
     E_weight_decay, FC_weight_decay = 0.01, 0.01
     ```

   - data hyperparameter

     ```python
     #(취급액, 판매량) 중 y변수로 어떤 것을 사용할 것인지 나타냅니다. 
     y_col_name = "판매량"
     
     # 각 데이터의 전처리 전략을 나타냅니다
     # category데이터를 embedding vector로 변환하고 싶으면, 아래과 같이 표기하면 됩니다. embedding_size는 임베딩 벡터의 크기, min_freq는 최소 빈도수와 관련된 수치로서 이 숫자보다 높은 빈도수로 나올때 하나의 카테고리로 인정합니니다. ("category_embedding", embedding_size, min_freq)
     
     # category데이터를 one-hot vector로 변환하고 싶으면 아래와 같이 표기하면 됩니다. min_freq의 의미는 위와 동일합니다.("category_onehot", min_freq)
     
     # numerical 데이터를 (-1,1) 범위로 min_max transformation해서 사용하고 싶으면 ("numerical_minmax",)적고 그대로 사용하고 싶으면 ("numerical", )을 적습니다.
     
     # numerical data를 embedding해서 사용하고 싶으면, 아래처럼 적습니다.  embedding_size는 임베딩 벡터 크기입니다.("numerical_embedding", embedding_size)
     
     # 상품군, 마더코드, 상품코드는 반드시 category_embedding을 사용해야합니다.
     # 최적의 편성표를 구하는 opt메소드를 활용하기 위해서는 모든 값을 embedding 해야합니다. 그리고 "Seq 방송 개수"와 "하루방송 수" 변수를 사용해야합니다.
     info = \
     {"월": ("category_embedding",20,2), 
      "노출(분)_all": ("numerical_minmax",)...}
     
     # 최종적으로 사용하지 않을 열을 고릅니다.
     drop = ["노출(분)_all"]
     
     # embedding 벡터로 변환한것을, 그냥 concat할것인지 그룹별로 sum할것인지 선택할 수 있습니다.
     # 최적의 편성표를 구하는 opt메소드를 활용하기 위해서는 반드시 concat=True 해야합니다.
     concat = True
     
     # embedding_sum 전략을 선택했을때, group별로 sum을 하는데 어떻게 그룹을 지을 것인지 나타내는 변수입니다. key 이름은 중요하지 않고 value에 무엇이 들어갔는지가 중요합니다.
     embedding_set = {"상품": ['마더코드', '상품군', '브랜드', '상품코드']}
     
     # embedding 벡터의 전체적인 크기를 줄여주는 regularizer가 training loss에 들어가는데 변수별 embedding 벡터에 곱해지는 패널티 계수의 크기를 정합니다. 크기가 클수록 패널티가 높아져서 embedding 벡터 크기가 작아집니다.
     reg_coef = {'월': 0.01, '시간': 0.01, ...}
     
     # embedding 벡터를 만들고 나서 최종적으로 앞에 곱해지는 계수입니다. 중요한 변수일수록 계수를 높혀 영향력을 높혀줄 수 있습니다.
     coef = {'월': 1, '시간': 1, '방송요일': 1, '연속 휴일': 1}
     
     #  preprocess2_test(train){num}_{num}.csv 데이터들 중 데이터를 사용할지 선택합니다. {num}_{num}에 해당하는 숫자를 넣어주면 됩니다. num의 의미는 2.데이터 전처리2.ipynb파일에 있습니다.
     num = "80_50"
     
     # 훈련할때 유사한 이름을 가진 상품군, 상품코드, 마더코드에 대해서 훈련을 진행하는데 훈련시킬 유사도의 하한을 정합니다. 아래 경우 0.8 유사도 이상을 나타내는 경우 유사도 훈련을 진행합니다.
     lower_sim = 0.8
     
     # 한 제품당 여러개의 유사한 제품이 존재하는데, lower_sim = 0.8, rank_sim_train = 1일 경우 0.8보다 높은 유사도를 나타내는 유사 제품 중 1번째로 높은 유사도를 나타내는 제품까지만 유사도 훈련을 진행합니다.
     rank_sim_train = 1
     
     # y값의 outlier의 영향을 줄이기 위해 max_y값을 임의로 설정했습니다.
     max_y = 10000
     ```

   - fix hyperparameter(거의 바꾸지 않아도 되는 hyper parameter입니다.)

     ```python
     # 사용하길 원하는 GPU 번호
     GPU_NUM = 0 
     
     # reproduce를 위한 seed number입니다.
     random_state = 777 
     
     # 결과를 저장 폴더 경로입니다.
     save_loc = "/home/ljh5694/tmp/result/original" 
     
     # print되는 결과가 txt파일로 저장되는데 그 위치입니다.
     save_file_name = "original.txt" 
     
     # train데이터를 validation set과 train set으로 분리하는데 그 비율을 나타냅니다.
     validation_ratio = 0.10 
     
     # 훈련시킬 에폭입니다.
     EPOCH = 60000 
     
     # 훈련시킬 배치 크기입니다.
     BATCH_SIZE = 10000 
     ```

3. initialize part

   - gpu설정, 필요한 package import 등 학습을 위한 initalization이 이루어집니다.

4. fitting, test part

   - from util._1_FC_based_class import FCClass 처럼 import한 class object를 생성, fit, predict, optimize method를 차례로 호출합니다.

   

### 5-2. main_test.py

1. main_test에서는 train된 모델로 부터 예측값을 산출합니다. 모든 hyperparameter를 train과 동일하게 하고 epoch만 1로 해서 test상태임을 표시합니다. 

2. 실행 후에는 예측값(test_result.csv), 최적 편성표(opt_plan.csv)이 각각 save_loc에 저장됩니다.




